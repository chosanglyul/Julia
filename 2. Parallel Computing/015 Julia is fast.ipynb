{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\u001b[2K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaComputing/JuliaAcademyData.jl`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25h"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[?25h[1mFetching:\u001b[22m\u001b[39m [========================================>]  100.0 %"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.4/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.4/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m Activating\u001b[22m\u001b[39m environment at `~/.julia/packages/JuliaAcademyData/3C2GY/courses/Parallel_Computing/Project.toml`\n"
     ]
    }
   ],
   "source": [
    "import Pkg; Pkg.add(Pkg.PackageSpec(url=\"https://github.com/JuliaComputing/JuliaAcademyData.jl\"))\n",
    "using JuliaAcademyData; activate(\"Parallel_Computing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Julia is fast\n",
    "\n",
    "Very often, benchmarks are used to compare languages.  These benchmarks can\n",
    "lead to long discussions, first as to exactly what is being benchmarked and\n",
    "secondly what explains the differences.  These simple questions can sometimes\n",
    "get more complicated than you at first might imagine.\n",
    "\n",
    "The purpose of this notebook is for you to see a simple benchmark for\n",
    "yourself.\n",
    "\n",
    "(This material began life as a wonderful lecture by Steven Johnson at MIT:\n",
    "[Boxes and registers](https://github.com/stevengj/18S096/blob/master/lectures/lecture1/Boxes-and-registers.ipynb))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline of this notebook\n",
    "\n",
    "- Define the sum function\n",
    "- Implementations & benchmarking of sum in...\n",
    "    - Julia (built-in)\n",
    "    - Julia (hand-written)\n",
    "    - C (hand-written)\n",
    "    - python (built-in)\n",
    "    - python (numpy)\n",
    "    - python (hand-written)\n",
    "- Towards exploiting parallelism with Julia\n",
    "    - Allowing for floating point associativity\n",
    "    - Making use of four cores at once: built-in\n",
    "    - Making use of four cores at once: hand-written\n",
    "- Summary of benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `sum`: An easy enough function to understand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the  **sum** function `sum(a)`, which computes\n",
    "$$\n",
    "\\mathrm{sum}(a) = \\sum_{i=1}^n a_i,\n",
    "$$\n",
    "where $n$ is the length of `a`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000000-element Array{Float64,1}:\n",
       " 0.9164315962038878\n",
       " 0.37301961556222496\n",
       " 0.44705137703347275\n",
       " 0.3342220772459985\n",
       " 0.38398867852017937\n",
       " 0.7219645648092967\n",
       " 0.7302818832599542\n",
       " 0.9114207992801229\n",
       " 0.883009797805091\n",
       " 0.5369992661389493\n",
       " 0.3618269446580824\n",
       " 0.7303833995943245\n",
       " 0.2322321754236525\n",
       " ⋮\n",
       " 0.7436360910305535\n",
       " 0.5781368368196613\n",
       " 0.17205257402855345\n",
       " 0.5247763203639646\n",
       " 0.8986867590964618\n",
       " 0.1723772424582013\n",
       " 0.8213696394389354\n",
       " 0.44231131077081765\n",
       " 0.9984650838001967\n",
       " 0.9986306355098091\n",
       " 0.522523990681141\n",
       " 0.15007418305575326"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = rand(10^7) # 1D vector of random numbers, uniform on [0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.99931302335025e6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expected result is ~0.5 * 10^7, since the mean of each entry is 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking a few ways in a few languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.004601 seconds (1 allocation: 16 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.99931302335025e6"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.004008 seconds (1 allocation: 16 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.99931302335025e6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.005939 seconds (1 allocation: 16 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.99931302335025e6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time sum(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `@time` macro can yield noisy results, so it's not our best choice for benchmarking!\n",
    "\n",
    "Luckily, Julia has a `BenchmarkTools.jl` package to make benchmarking easy and accurate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     4.520 ms (0.00% GC)\n",
       "  median time:      5.707 ms (0.00% GC)\n",
       "  mean time:        5.731 ms (0.00% GC)\n",
       "  maximum time:     7.511 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          871\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark sum($a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Julia Built-in\n",
    "\n",
    "So that's the performance of Julia's built-in sum — but that could be doing any number of tricks to be fast, including not using Julia at all in the first place! Of course, it is indeed written in Julia, but would it perform if we write a naive implementation ourselves?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "sum(a::<b>AbstractArray</b>; <i>dims</i>) in Base at <a href=\"https://github.com/JuliaLang/julia/tree/v1.4.1/base/reducedim.jl#L652\" target=\"_blank\">reducedim.jl:652</a>"
      ],
      "text/plain": [
       "sum(a::AbstractArray; dims) in Base at reducedim.jl:652"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@which sum(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save these benchmark results to a dictionary so we can start keeping track of them and comparing them down the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     4.479 ms (0.00% GC)\n",
       "  median time:      5.862 ms (0.00% GC)\n",
       "  mean time:        5.974 ms (0.00% GC)\n",
       "  maximum time:     8.063 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          836\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_bench = @benchmark sum($a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 1 entry:\n",
       "  \"Julia built-in\" => 4.47907"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = Dict()\n",
    "d[\"Julia built-in\"] = minimum(j_bench.times) / 1e6\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Julia (hand-written)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mysum (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mysum(A)\n",
    "    s = 0.0\n",
    "    for a in A\n",
    "        s += a\n",
    "    end\n",
    "    return s\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     10.139 ms (0.00% GC)\n",
       "  median time:      10.956 ms (0.00% GC)\n",
       "  mean time:        11.011 ms (0.00% GC)\n",
       "  maximum time:     12.968 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          454\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_bench_hand = @benchmark mysum($a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 2 entries:\n",
       "  \"Julia hand-written\" => 10.1385\n",
       "  \"Julia built-in\"     => 4.47907"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"Julia hand-written\"] = minimum(j_bench_hand.times) / 1e6\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that's about 2x slower than the builtin definition. We'll see why later on.\n",
    "\n",
    "But first: is this fast?  How would we know?  Let's compare it to some other languages..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  3. The C language\n",
    "\n",
    "C is often considered the gold standard: difficult on the human, nice for the machine. Getting within a factor of 2 of C is often satisfying. Nonetheless, even within C, there are many kinds of optimizations possible that a naive C writer may or may not get the advantage of.\n",
    "\n",
    "The current author does not speak C, so he does not read the cell below, but is happy to know that you can put C code in a Julia session, compile it, and run it. Note that the `\"\"\"` wrap a multi-line string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c_sum (generic function with 1 method)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Libdl\n",
    "C_code = \"\"\"\n",
    "    #include <stddef.h>\n",
    "    double c_sum(size_t n, double *X) {\n",
    "        double s = 0.0;\n",
    "        for (size_t i = 0; i < n; ++i) {\n",
    "            s += X[i];\n",
    "        }\n",
    "        return s;\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "const Clib = tempname()   # make a temporary file\n",
    "\n",
    "\n",
    "# compile to a shared library by piping C_code to gcc\n",
    "# (works only if you have gcc installed):\n",
    "\n",
    "open(`gcc -fPIC -O3 -msse3 -xc -shared -o $(Clib * \".\" * Libdl.dlext) -`, \"w\") do f\n",
    "    print(f, C_code)\n",
    "end\n",
    "\n",
    "# define a Julia function that calls the C function:\n",
    "c_sum(X::Array{Float64}) = ccall((\"c_sum\", Clib), Float64, (Csize_t, Ptr{Float64}), length(X), X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.999313023350245e6"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_sum(a) ≈ sum(a) # type \\approx and then <TAB> to get the ≈ symbolb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now benchmark the C code directly from Julia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     10.088 ms (0.00% GC)\n",
       "  median time:      10.878 ms (0.00% GC)\n",
       "  mean time:        10.943 ms (0.00% GC)\n",
       "  maximum time:     12.986 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          457\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_bench = @benchmark c_sum($a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 3 entries:\n",
       "  \"C\"                  => 10.0877\n",
       "  \"Julia hand-written\" => 10.1385\n",
       "  \"Julia built-in\"     => 4.47907"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"C\"] = minimum(c_bench.times) / 1e6  # in milliseconds\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Python's built in `sum`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `PyCall` package provides a Julia interface to Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyCall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <built-in function sum>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the Python built-in \"sum\" function:\n",
    "pysum = pybuiltin(\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.999313023350245e6"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pysum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pysum(a) ≈ sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  352 bytes\n",
       "  allocs estimate:  7\n",
       "  --------------\n",
       "  minimum time:     1.285 s (0.00% GC)\n",
       "  median time:      1.312 s (0.00% GC)\n",
       "  mean time:        1.313 s (0.00% GC)\n",
       "  maximum time:     1.341 s (0.00% GC)\n",
       "  --------------\n",
       "  samples:          4\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_list_bench = @benchmark $pysum($a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 4 entries:\n",
       "  \"C\"                  => 10.0877\n",
       "  \"Julia hand-written\" => 10.1385\n",
       "  \"Julia built-in\"     => 4.47907\n",
       "  \"Python built-in\"    => 1285.5"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"Python built-in\"] = minimum(py_list_bench.times) / 1e6\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Python: `numpy`\n",
    "\n",
    "`numpy` is an optimized C library, callable from Python.\n",
    "It may be installed within Julia as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conda.add(\"numpy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: `getindex(o::PyObject, s::AbstractString)` is deprecated in favor of dot overloading (`getproperty`) so elements should now be accessed as e.g. `o.\"s\"` instead of `o[\"s\"]`.\n",
      "│   caller = top-level scope at In[28]:1\n",
      "└ @ Core In[28]:1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  352 bytes\n",
       "  allocs estimate:  7\n",
       "  --------------\n",
       "  minimum time:     3.811 ms (0.00% GC)\n",
       "  median time:      4.192 ms (0.00% GC)\n",
       "  mean time:        4.255 ms (0.00% GC)\n",
       "  maximum time:     5.483 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          1174\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_sum = pyimport(\"numpy\")[\"sum\"]\n",
    "\n",
    "py_numpy_bench = @benchmark $numpy_sum($a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.999313023350249e6"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_sum(a) ≈ sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 5 entries:\n",
       "  \"C\"                  => 10.0877\n",
       "  \"Julia hand-written\" => 10.1385\n",
       "  \"Python numpy\"       => 3.81148\n",
       "  \"Julia built-in\"     => 4.47907\n",
       "  \"Python built-in\"    => 1285.5"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"Python numpy\"] = minimum(py_numpy_bench.times) / 1e6\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Python, hand-written"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <function py_sum at 0x7f833a787790>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py\"\"\"\n",
    "def py_sum(A):\n",
    "    s = 0.0\n",
    "    for a in A:\n",
    "        s += a\n",
    "    return s\n",
    "\"\"\"\n",
    "\n",
    "sum_py = py\"py_sum\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  352 bytes\n",
       "  allocs estimate:  7\n",
       "  --------------\n",
       "  minimum time:     1.583 s (0.00% GC)\n",
       "  median time:      1.611 s (0.00% GC)\n",
       "  mean time:        1.612 s (0.00% GC)\n",
       "  maximum time:     1.644 s (0.00% GC)\n",
       "  --------------\n",
       "  samples:          4\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_hand = @benchmark $sum_py($a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.999313023350245e6"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_py(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_py(a) ≈ sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 6 entries:\n",
       "  \"C\"                   => 10.0877\n",
       "  \"Julia hand-written\"  => 10.1385\n",
       "  \"Python numpy\"        => 3.81148\n",
       "  \"Python hand-written\" => 1583.4\n",
       "  \"Julia built-in\"      => 4.47907\n",
       "  \"Python built-in\"     => 1285.5"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"Python hand-written\"] = minimum(py_hand.times) / 1e6\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python numpy................3.8\n",
      "Julia built-in..............4.5\n",
      "C..........................10.1\n",
      "Julia hand-written.........10.1\n",
      "Python built-in..........1285.5\n",
      "Python hand-written......1583.4\n"
     ]
    }
   ],
   "source": [
    "for (key, value) in sort(collect(d), by=last)\n",
    "    println(rpad(key, 25, \".\"), lpad(round(value; digits=1), 6, \".\"))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We seem to have three different performance classes here: The numpy and Julia\n",
    "builtins are leading the pack, followed by the hand-written Julia and C\n",
    "definitions. Those seem to be about 2x slower.  And then we have the much much\n",
    "slower Python definitions over 100x slower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploiting parallelism with Julia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fact that our hand-written Julia solution was almost an even multiple of\n",
    "2x slower than the builtin solutions is a big clue: perhaps theres some sort\n",
    "of 2x parallelism going on here?\n",
    "\n",
    "(In fairness, there are ways to exploit parallelism in other languages, too,\n",
    "but for brevity we won't cover them)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Julia (allowing floating point associativity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `for` loop\n",
    "\n",
    "```julia\n",
    "for a in A\n",
    "    s += a\n",
    "end\n",
    "```\n",
    "\n",
    "defines a very strict _order_ to the summation: Julia follows exactly what you\n",
    "wrote and adds the elements of `A` to the result `s` in the order it iterates.\n",
    "Since floating point numbers aren't associative, a rearrangement here would\n",
    "change the answer — and Julia is loathe to give you different answer than\n",
    "the one you asked for.\n",
    "\n",
    "You can, however, tell Julia to relax that rule and allow for associativity\n",
    "with the `@fastmath` macro. This might allow Julia to rearrange the sum in an\n",
    "advantageous manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mysum_fast (generic function with 1 method)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mysum_fast(A)\n",
    "    s = 0.0\n",
    "    for a in A\n",
    "        @fastmath s += a\n",
    "    end\n",
    "    s\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     4.538 ms (0.00% GC)\n",
       "  median time:      5.749 ms (0.00% GC)\n",
       "  mean time:        5.875 ms (0.00% GC)\n",
       "  maximum time:     7.877 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          850\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_bench_hand_fast = @benchmark mysum_fast($a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.999313023350276e6"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mysum_fast(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 7 entries:\n",
       "  \"C\"                       => 10.0877\n",
       "  \"Julia hand-written\"      => 10.1385\n",
       "  \"Python numpy\"            => 3.81148\n",
       "  \"Python hand-written\"     => 1583.4\n",
       "  \"Julia built-in\"          => 4.47907\n",
       "  \"Python built-in\"         => 1285.5\n",
       "  \"Julia hand-written fast\" => 4.53804"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"Julia hand-written fast\"] = minimum(j_bench_hand_fast.times) / 1e6\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Distributed Julia (built-in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take this one step further: nearly every modern computer these days has\n",
    "multiple cores. All the above solutions are working one core hard, but all the\n",
    "others are just sitting by idly. Let's put them to work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using Pkg\n",
    "#Pkg.add(\"DistributedArrays\")\n",
    "using Distributed\n",
    "using DistributedArrays\n",
    "addprocs(4)\n",
    "@sync @everywhere workers() include(\"/etc/julia/startup.jl\")\n",
    "@everywhere using DistributedArrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  13.30 KiB\n",
       "  allocs estimate:  364\n",
       "  --------------\n",
       "  minimum time:     3.614 ms (0.00% GC)\n",
       "  median time:      4.677 ms (0.00% GC)\n",
       "  mean time:        4.674 ms (0.00% GC)\n",
       "  maximum time:     6.156 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          1067\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adist = distribute(a)\n",
    "j_bench_dist = @benchmark sum($adist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 9 entries:\n",
       "  \"C\"                       => 10.0877\n",
       "  \"Julia hand-written\"      => 10.1385\n",
       "  \"Python numpy\"            => 3.81148\n",
       "  \"Python hand-written\"     => 1583.4\n",
       "  \"Julia built-in\"          => 4.47907\n",
       "  \"Python built-in\"         => 1285.5\n",
       "  \"Julia 4x built-in\"       => 3.61403\n",
       "  \"Julia 4x hand-written\"   => 4.25633\n",
       "  \"Julia hand-written fast\" => 4.53804"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"Julia 4x built-in\"] = minimum(j_bench_dist.times) / 1e6\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Distributed Julia (hand-written)\n",
    "\n",
    "Ok, that might be cheating, too — it's again just calling a library\n",
    "function. Is it possible to write distributed sum ourselves?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mysum_dist (generic function with 1 method)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mysum_dist(a::DArray)\n",
    "    r = Array{Future}(undef, length(procs(a)))\n",
    "    for (i, id) in enumerate(procs(a))\n",
    "        r[i] = @spawnat id sum(localpart(a))\n",
    "    end\n",
    "    return sum(fetch.(r))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  19.38 KiB\n",
       "  allocs estimate:  542\n",
       "  --------------\n",
       "  minimum time:     3.718 ms (0.00% GC)\n",
       "  median time:      5.209 ms (0.00% GC)\n",
       "  mean time:        5.154 ms (0.00% GC)\n",
       "  maximum time:     8.835 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          967\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_bench_hand_dist = @benchmark mysum_dist($adist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 9 entries:\n",
       "  \"C\"                       => 10.0877\n",
       "  \"Julia hand-written\"      => 10.1385\n",
       "  \"Python numpy\"            => 3.81148\n",
       "  \"Python hand-written\"     => 1583.4\n",
       "  \"Julia built-in\"          => 4.47907\n",
       "  \"Python built-in\"         => 1285.5\n",
       "  \"Julia 4x built-in\"       => 3.61403\n",
       "  \"Julia 4x hand-written\"   => 3.71844\n",
       "  \"Julia hand-written fast\" => 4.53804"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"Julia 4x hand-written\"] = minimum(j_bench_hand_dist.times) / 1e6\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia 4x built-in...........3.6\n",
      "Julia 4x hand-written.......3.7\n",
      "Python numpy................3.8\n",
      "Julia built-in..............4.5\n",
      "Julia hand-written fast.....4.5\n",
      "C..........................10.1\n",
      "Julia hand-written.........10.1\n",
      "Python built-in..........1285.5\n",
      "Python hand-written......1583.4\n"
     ]
    }
   ],
   "source": [
    "for (key, value) in sort(collect(d), by=last)\n",
    "    println(rpad(key, 25, \".\"), lpad(round(value; digits=1), 6, \".\"))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key take-aways\n",
    "\n",
    "* Julia allows for serial C-like performance, even with hand-written functions\n",
    "* Julia allows us to exploit many forms of parallelism to further improve performance. We demonstrated:\n",
    "    * Single-processor parallelism with SIMD\n",
    "    * Multi-process parallelism with DistributedArrays\n",
    "* But there are many other ways to express parallelism, too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.1",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
